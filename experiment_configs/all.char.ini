[main]
name="single BiRNN + learnable WE"
output="experiment_outputs/charlvl_birnn_we.crf2"
tf_manager=<tf_manager>

train_dataset=<train_data>
val_dataset=<val_data>
test_datasets=[<val_data>]

runners=[<runner>]
trainer=<trainer>
evaluation=[("mwe", "mwe", evaluators.accuracy.Accuracy), ("mwe", "mwe", <mwef1_tok>), ("mwe", "mwe", <mwef1_mwe>)]

batch_size=64
runners_batch_size=10
epochs=300

validation_period=5000
logging_period=500
overwrite_output_dir=True

[mwef1_tok]
class=evaluators.mwe.MWEEvaluator
name="f1_tok"
mode="tok_based"
tractable=True
metric="f-measure"

[mwef1_mwe]
class=evaluators.mwe.MWEEvaluator
name="f1_mwe"
mode="mwe_based"
tractable=True
metric="f-measure"

[tf_manager]
class=tf_manager.TensorFlowManager
num_sessions=1
num_threads=8

[mwe_preprocess]
class=processors.mwe.MWELabelPreprocessor

[mwe_postprocess]
class=processors.mwe.MWELabelPostprocessor

[train_data]
class=dataset.load_dataset_from_files
s_forms="data/CS/train.forms"
s_lemmas="data/CS/train.lemmas"
s_tags="data/CS/train.tags"
s_mwe="data/CS/train.mwe"
preprocessors=[("forms", "forms_char", processors.helpers.preprocess_char_two_level), ("lemmas", "lemmas_char", processors.helpers.preprocess_char_two_level), ("tags", "tags_char", processors.helpers.preprocess_char_two_level), ("mwe", "mwe_pre", <mwe_preprocess>)]

[val_data]
class=dataset.load_dataset_from_files
s_forms="data/CS/test.forms"
s_lemmas="data/CS/train.lemmas"
s_tags="data/CS/train.tags"
s_mwe="data/CS/test.mwe"
preprocessors=[("forms", "forms_char", processors.helpers.preprocess_char_two_level), ("lemmas", "lemmas_char", processors.helpers.preprocess_char_two_level), ("tags", "tags_char", processors.helpers.preprocess_char_two_level), ("mwe", "mwe_pre", <mwe_preprocess>)]

[char_vocab]
class=vocabulary.from_dataset_char
datasets=[<train_data>]
series_ids=["forms_char", "lemmas_char", "tags_char"]
max_size=2000

[mwe_vocab]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["mwe_pre"]
max_size=50

[input_seq]
class=model.sequence.CharacterLevelFactorSequence
name="input"
embedding_sizes=[100, 100, 100]
data_ids=["forms_char", "lemmas_char", "tags_char"]
;max_length=200
vocabularies=[<char_vocab>, <char_vocab>, <char_vocab>]

; encoder type
encoder_type="recurrent"
;encoder_type="convolutional"

; recurrent opts
rnn_cell="GRU"
;rnn_cell="LSTM"


; convolutional opts
;conv_filters=[2,3,4,5]

; pooling (both)
pooling="maxpool"
;pooling="average"

[birnn_encoder]
class=encoders.RecurrentEncoder
name="sentence_encoder"
input_sequence=<input_seq>
rnn_size=300
rnn_cell="LSTM"
rnn_direction="bidirectional"
dropout_keep_prob=0.8

[fb_encoder]
class=encoders.facebook_conv.SentenceEncoder
name="sentence_encoder"
input_sequence=<input_seq>
conv_features=300
encoder_layers=3
kernel_width=3
dropout_keep_prob=0.8

[transformer_encoder]
class=encoders.transformer.TransformerEncoder
name="sentence_encoder"
input_sequence=<input_seq>
ff_hidden_size=450
depth=3
n_heads=10
dropout_keep_prob=0.8

[crf_decoder]
class=decoders.sequence_labeler.CRFLabeler
name="tagger"
encoders=[<encoder>]
data_id="mwe_pre"
dropout_keep_prob=0.8
vocabulary=<mwe_vocab>

[base_decoder]
class=decoders.sequence_labeler.SequenceLabeler
name="tagger"
encoders=[<encoder>]
data_id="mwe_pre"
dropout_keep_prob=0.8
vocabulary=<mwe_vocab>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0

[crf_runner]
class=runners.crf_runner.CRFRunner
decoder=<crf_decoder>
output_series="mwe"
postprocess=<mwe_postprocess>

[base_runner]
class=runners.label_runner.LabelRunner
decoder=<base_decoder>
output_series="mwe"
postprocess=<mwe_postprocess>
