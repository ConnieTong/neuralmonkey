[main]
name="single BiRNN + learnable WE"
output="experiment_outputs/birnn_we.crf2"
tf_manager=<tf_manager>

train_dataset=<train_data>
val_dataset=<val_data>
test_datasets=[<val_data>]

runners=[<runner>]
trainer=<trainer>
evaluation=[("mwe", "mwe", evaluators.accuracy.Accuracy), ("mwe", "mwe", <mwef1_tok>), ("mwe", "mwe", <mwef1_mwe>)]

batch_size=64
runners_batch_size=10
epochs=300

validation_period=5000
logging_period=500
overwrite_output_dir=True

[mwef1_tok]
class=evaluators.mwe.MWEEvaluator
name="f1_tok"
mode="tok_based"
tractable=True
metric="f-measure"

[mwef1_mwe]
class=evaluators.mwe.MWEEvaluator
name="f1_mwe"
mode="mwe_based"
tractable=True
metric="f-measure"

[tf_manager]
class=tf_manager.TensorFlowManager
num_sessions=1
num_threads=8

[mwe_preprocess]
class=processors.mwe.MWELabelPreprocessor

[mwe_postprocess]
class=processors.mwe.MWELabelPostprocessor

[train_data]
class=dataset.load_dataset_from_files
s_forms="data/CS/train.forms"
s_lemmas="data/CS/train.lemmas"
s_tags="data/CS/train.tags"
s_mwe="data/CS/train.mwe"
preprocessors=[("mwe", "mwe_pre", <mwe_preprocess>)]

[val_data]
class=dataset.load_dataset_from_files
s_forms="data/CS/test.forms"
s_lemmas="data/CS/test.lemmas"
s_tags="data/CS/test.tags"
s_mwe="data/CS/test.mwe"
preprocessors=[("mwe", "mwe_pre", <mwe_preprocess>)]

[forms_vocab]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["forms"]
max_size=50000

[lemmas_vocab]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["lemmas"]
max_size=50000

[tags_vocab]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["tags"]
max_size=100

[mwe_vocab]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["mwe_pre"]
max_size=50

[input_seq]
class=model.sequence.EmbeddedFactorSequence
name="input"
embedding_sizes=[100, 100, 100]
data_ids=["forms", "lemmas", "tags"]
;max_length=200
vocabularies=[<forms_vocab>, <lemmas_vocab>, <tags_vocab>]

;[lemmas_seq]
;class=model.sequence.EmbeddedSequence
;name="input_lemmas"
;embedding_size=100
;data_id="lemmas"
;vocabulary=<lemmas_vocab>

;[tags_seq]
;class=model.sequence.EmbeddedSequence
;name="input_tags"
;embedding_size=100
;data_id="tags"
;vocabulary=<tags_vocab>

[birnn_encoder]
class=encoders.RecurrentEncoder
name="sentence_encoder"
input_sequence=<input_seq>
rnn_size=300
rnn_cell="LSTM"
rnn_direction="bidirectional"
dropout_keep_prob=0.8

[fb_encoder]
class=encoders.facebook_conv.SentenceEncoder
name="sentence_encoder"
input_sequence=<input_seq>
conv_features=300
encoder_layers=3
kernel_width=3
dropout_keep_prob=0.8

[transformer_encoder]
class=encoders.transformer.TransformerEncoder
name="sentence_encoder"
input_sequence=<input_seq>
ff_hidden_size=450
depth=3
n_heads=10
dropout_keep_prob=0.8

[crf_decoder]
class=decoders.sequence_labeler.CRFLabeler
name="tagger"
encoders=[<encoder>]
data_id="mwe_pre"
dropout_keep_prob=0.8
vocabulary=<mwe_vocab>

[base_decoder]
class=decoders.sequence_labeler.SequenceLabeler
name="tagger"
encoders=[<encoder>]
data_id="mwe_pre"
dropout_keep_prob=0.8
vocabulary=<mwe_vocab>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8
clip_norm=1.0

[crf_runner]
class=runners.crf_runner.CRFRunner
decoder=<crf_decoder>
output_series="mwe"
postprocess=<mwe_postprocess>

[base_runner]
class=runners.label_runner.LabelRunner
decoder=<base_decoder>
output_series="mwe"
postprocess=<mwe_postprocess>
