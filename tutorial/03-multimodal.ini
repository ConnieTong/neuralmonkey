[vars]
proj_prefix="."
exp_prefix="{proj_prefix}/tutorial"
data_prefix="/net/me/merkur3/varis/tspec-workdir/nmonkey-mtm2018/tutorial-data"

dropout=0.7


[main]
name="Multimodal Translation"
output="{exp_prefix}/multimodal"
overwrite_output_dir=True
batch_size=64
epochs=100
tf_manager=<tf_manager>
train_dataset=<train_data>
val_dataset=<val_data>
trainer=<trainer>
runners=[<greedy_runner>, <perplexity_runner>]
postprocess=None
evaluation=[("perplexity", "target", <perplexity>), ("target", "target", evaluators.BLEU), ("target", "target", evaluators.ChrF3)]
logging_period=50
validation_period=500
runners_batch_size=64
random_seed=42

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1
minimize_metric=False

[perplexity]
class=evaluators.AverageEvaluator
name="perplexity"


# DATA

[train_data]
class=dataset.load_dataset_from_files
########
s_images=("{data_prefix}/dummy-train.txt", <imagenet_reader>)
########
s_target="{data_prefix}/ar2en-train.tgt.txt"
s_source="{data_prefix}/ar2en-train.src.txt"
preprocessors=[("source", "source_char", processors.helpers.preprocess_char_based), ("target", "target_char", processors.helpers.preprocess_char_based)]
lazy=True

[val_data]
class=dataset.load_dataset_from_files
########
s_images=("{data_prefix}/dummy-val.txt", <imagenet_reader>)
########
s_target="{data_prefix}/ar2en-eval.tgt.txt"
s_source="{data_prefix}/ar2en-eval.src.txt"
preprocessors=[("source", "source_char", processors.helpers.preprocess_char_based), ("target", "target_char", processors.helpers.preprocess_char_based)]

[vocabulary]
class=vocabulary.from_dataset
datasets=[<train_data>]
series_ids=["source_char", "target_char"]
max_size=500
overwrite=True
save_file="{exp_prefix}/seq2seq_attention/vocabulary.txt"

#################
[imagenet_reader]
; This reader is used to read the image
; representations produced by the imagenet
class=readers.numpy_reader.from_file_list
prefix="{data_prefix}/images"
suffix=".npz"
#################


# MODEL

###############
[image_encoder]
class=encoders.numpy_stateful_filler.SpatialFiller
input_shape=[8, 8, 2048]
data_id="images"
ff_hidden_dim=256
projection_dim=128
###############

[input_sequence]
class=model.sequence.EmbeddedSequence
max_length=30
embedding_size=128
data_id="source_char"
vocabulary=<vocabulary>

[encoder]
class=encoders.recurrent.RecurrentEncoder
input_sequence=<input_sequence>
rnn_size=64
rnn_cell="LSTM"
rnn_direction="bidirectional"
dropout_keep_prob=$dropout

[decoder]
class=decoders.Decoder
name="decoder"
##########
encoders=[<encoder>, <image_encoder>]
attentions=[<encoder_attention>, <image_attention>]
##########
vocabulary=<vocabulary>
data_id="target_char"
rnn_size=256
rnn_cell="LSTM"
max_output_len=30
dropout_keep_prob=$dropout
embeddings_source=<input_sequence>

[encoder_attention]
class=attention.Attention
encoder=<encoder>

#################
[image_attention]
class=attention.Attention
encoder=<image_encoder>
#################

# RUNNERS & TRAINERS

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
optimizer=<adam>
clip_norm=1.0

[adam]
class=tf.contrib.opt.LazyAdamOptimizer
beta1=0.9
beta2=0.997
epsilon=1.0e-9
learning_rate=1e-4

[greedy_runner]
class=runners.runner.GreedyRunner
decoder=<decoder>
output_series="target"
postprocess=processors.helpers.postprocess_char_based

[perplexity_runner]
class=runners.PerplexityRunner
decoder=<decoder>
output_series="perplexity"
